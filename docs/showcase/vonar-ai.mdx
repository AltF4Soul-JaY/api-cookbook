---
title: "Vonar.ai - Voice AI Assistant"
description: "Voice-based AI assistant for customer support using Sonar API for real-time intelligence"
sidebar_position: 2
---

# Vonar.ai - Voice AI Assistant

Vonar.ai is an AI-powered voice agent that answers inbound calls, handles support requests, and instantly finds answers using real-time search ‚Äî all without a human.


üöÄ Inspiration We were frustrated by how bad most inbound call experiences are ‚Äî long wait times, robotic phone trees, and irrelevant answers. At the same time, most businesses don‚Äôt have the resources to build a full AI voice stack. Vonar.ai was born from that gap: we wanted to create a voice agent that actually understands callers, acts fast, and gets smarter with real-time knowledge ‚Äî without needing a team of engineers to set it up.

‚∏ª ü§ñ What it does

Vonar.ai is a voice-based AI assistant that answers inbound calls, triages requests, and responds using real-time, search-powered intelligence. It can: ‚Ä¢ Answer questions about policies, outages, or product info using Perplexity‚Äôs Sonar API ‚Ä¢ Handle account, tech, or service-related queries in a guided, secure way ‚Ä¢ Mock advanced flows like authentication and ticket creation to simulate integrations ‚Ä¢ Escalate to human agents or inform users when they need a custom production setup

All while speaking naturally and keeping the experience smooth and on-brand. ‚∏ª üõ† How we built it ‚Ä¢ Voice pipeline: Built using Vapi.ai to power voice input/output with real-time LLM processing ‚Ä¢ LLM: We used Llama 4 via Groq for blazing-fast inference and plugged in Perplexity‚Äôs Sonar Pro as a real-time search tool ‚Ä¢ Tool integration: Designed custom tool calls that silently inject Sonar results into the LLM‚Äôs context mid-call ‚Ä¢ Frontend/Infra: Serverless backend with Netlify Functions, live audio/webhook streaming, and optional Redis caching for performance ‚Ä¢ Demo optimization: Built a system prompt + dynamic persona system for customized flows per org or use case ‚∏ª ‚öîÔ∏è Challenges we ran into ‚Ä¢ LLM prompt management: Keeping the system prompt concise while packing in real logic and disclaimers for mock/demo flows ‚Ä¢ Tool call timing: Ensuring that tool responses came back fast enough to avoid Vapi auto-ending the call due to silence ‚Ä¢ Auth & ticketing mocks: Simulating secure flows in a realistic way without violating trust or misleading the user ‚Ä¢ Silent lookups: Preventing the AI from ‚Äúbreaking character‚Äù when fetching from Sonar ‚Äî had to tune the tone and behavior closely ‚∏ª üèÜ Accomplishments that we‚Äôre proud of ‚Ä¢ Built a fully working inbound AI voice agent that can actually hold useful conversations, not just reroute calls ‚Ä¢ Seamlessly connected real-time search (Sonar) into a voice workflow ‚Äî almost no one does this live and cleanly ‚Ä¢ Delivered a usable demo that businesses could test with their own call flow in minutes ‚Ä¢ Optimized latency with Groq + Netlify + Redis to make everything feel snappy as hell

‚∏ª üìö What we learned ‚Ä¢ Fast voice UX needs ruthless simplicity and aggressive caching ‚Äî even 500ms of lag ruins the experience ‚Ä¢ People will forgive a lot if the voice is confident, clear, and useful ‚Äî tone matters more than people think ‚Ä¢ Vapi‚Äôs infrastructure is powerful but fragile if you miss even one config (like toolIds) ‚Ä¢ Real-time search + voice agents is a killer combo, especially for gov and compliance-heavy orgs ‚∏ª üöß What‚Äôs next for Vonar.ai ‚Ä¢ Pilot with gov-aligned orgs and service-heavy businesses like MSPs, SaaS platforms, or utilities ‚Ä¢ Production integrations with Jira Service Management and Salesforce for live ticketing + user auth ‚Ä¢ Deploy self-serve onboarding so any org can spin up a branded Vonar voice agent with their own FAQ link ‚Ä¢ Expand tool library to include weather, outage detection, gov databases, or internal knowledge base sync ‚Ä¢ Go-to-market: targeting Carahsoft channels, AI hackathons, and defense tech conferences for early traction